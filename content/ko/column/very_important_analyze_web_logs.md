---
date: 2025-02-20
draft: false
title: "웹의 전체 로그 분석은 왜 중요한가?"
description: "제로데이 공격, 크리덴셜 스터핑, 웹쉘 탐지 등 전체 웹로그 분석이 왜 중요한지를 알아봅니다."
featured_image: "cdn/column/very_important_analyze_web_logs.png"
tags: ["GET 방식", "POST 방식", "웹로그 분석", "보안", "PLURA-XDR"]
---

최근 보안 위협이 더욱 지능화되고, 여러 단계에 걸쳐 숨겨진 형태로 진행되는 **공격 기법**들이 늘어나고 있습니다. 단순히 특정 요청(GET/POST)에만 집중하기보다는, **웹의 전체 트래픽 로그**를 분석함으로써 더욱 깊이 있고 광범위한 보안 정보를 얻을 수 있습니다. 이번 글에서는 **제로데이 공격**, **크리덴셜 스터핑**, **웹쉘 탐지**, **파라메터 변조**와 같은 사례뿐 아니라, **전체 웹 로그** 분석이 갖는 중요성과 이를 통해 얻을 수 있는 보안 이점을 살펴보겠습니다.

![Web Traffic](https://blog.plura.io/cdn/column/very_important_analyze_web_logs.png)  
<!--more-->

---

## 왜 전체 웹 로그 분석이 중요한가?

### 1) 제로데이 또는 알려지지 않은 공격(Zero-Day Attack) 탐지
기존에 알려지지 않은 취약점을 이용한 공격인 제로데이(0-Day) 공격은, **알려진 시그니처나 룰 기반만으로는 탐지**하기 어렵습니다. 이때, **웹 로그 전체**를 분석하면 다음과 같은 이점이 있습니다:

- **이상 징후 분석**: 평소와 다른 패턴의 트래픽이나, 특정 자원에 집중되는 의심스러운 요청을 조기에 발견  
- **복합 공격 흐름 파악**: 여러 단계를 거쳐 이루어지는 신종 공격 또한 추적 가능  

신종 공격에 대비하기 위해서는 **이상 패턴 자체**를 빠르게 감지하는 능력이 필수이며, 이는 **전체 로그 분석**이 기반이 되어야 가능합니다.

### 2) 단일 패킷만으로는 알 수 없는 공격 식별
웹 공격은 때로는 **여러 번의 요청**을 통해 이루어집니다. 가장 대표적인 예가 **크리덴셜 스터핑**(Credential Stuffing)이나 **브루트포싱**(Brute Force)입니다.

- **개별 요청**만 본다면 단순한 ‘로그인 실패’ 정도로 보이지만,  
- **전체 로그 추이**를 보면 매우 많은 인증 시도나 특정 계정 공격이 포착  

이처럼 단순 에러나 로그인 실패 로그가 **동시다발적**으로 일어나는지, 특정 시간대에 몰려 있는지 등을 종합적으로 파악하는 것이 중요합니다.

### 3) 업로드된 웹쉘(WebShell) 경로 파악
APT(지능형 지속 위협) 공격의 초기 단계에서 자주 활용되는 수법 중 하나가 **웹쉘 업로드**입니다.  
- 파일 업로드 요청 로그, 서버 내부 경로 접근 로그 등을 **연속적으로** 추적  
- 웹쉘이 실제로 업로드되었는지, 이후 어떤 스크립트를 실행했는지 등 공격 흐름 전반 확인  

이러한 **흔적**들을 놓치지 않으려면 **웹 로그 전반**을 꼼꼼히 모니터링할 필요가 있습니다.

### 4) 파라메터 변조 공격(Parameter Tampering)
웹 애플리케이션의 `쿼리 스트링`, `POST Body`, `쿠키`, `헤더` 등에 담긴 파라메터를 의도적으로 변조하여 **비정상적인 동작**을 유도하는 공격 기법입니다.

- **가격 변조**, **권한 상승**, **부정 결제** 등 직접적인 피해로 이어질 가능성이 큼  
- 파라메터 변조를 시도하는 과정에서 **이상하게 긴 혹은 예외적인 값**이 반복적으로 등장하는 패턴을 로그 전체에서 발견할 수 있음  
- 특정 파일 업로드 파라메터, 관리자 전용 기능 파라메터 등을 노리기도 하므로 **전체 트래픽**에 대한 모니터링이 필수  

이처럼 공격자들은 정상적인 요청 형식을 가장해 파라메터를 살짝 바꾸어 보내므로, 개별 요청만 보면 단순 오타나 에러로 보일 수 있지만, **전체 로그**를 보면 패턴이 드러나는 경우가 많습니다.

### 5) 세션 하이재킹(Session Hijacking) 및 사용자 행위 분석
사용자 세션을 도용해 권한을 얻는 세션 하이재킹 등은 **특정 사용자가 평소에 보이지 않던 패턴**으로 접근하거나,  
**세션 쿠키**를 사용해 비정상적인 요청을 반복적으로 수행하는 형태로 이뤄집니다.

- **로그인/로그아웃 간격**, **페이지 이동 패턴**, **User-Agent**, **IP 변화** 등을 종합적으로 살펴보면, 정상 사용자와 공격자의 행동을 구분해 낼 수 있습니다.  
- 이러한 세션 정보도 결국 **전체 웹 로그** 안에서 다각도로 검토해야 하기 때문에 광범위한 분석이 필수적입니다.

### 6) 복합 공격(멀티벡터 공격) 대응
- 공격자는 **웹 + 호스트**(서버와 PC) 전반에서 취약점을 찾습니다.  
- 예컨대, 웹 어플리케이션 취약점 탐색 후 성공하면, 곧바로 내부 호스트로 침투하는 측면 이동 공격으로 추가 악성 활동을 시도합니다.  
- **전체 웹 로그**와 더불어 **호스트**의 전체 로그까지 상호 연동해 볼 경우, 공격 의도를 더욱 명확히 파악할 수 있습니다.

### 7) 봇 탐지(Bot Detection) 🤖
웹 애플리케이션에 **정상 사용자가 아닌 자동화된 프로그램**(크롤러, 스크래핑 도구, 악성 봇 등)이 접근하여  
비정상적인 트래픽을 발생시키거나 데이터를 무단으로 수집하는 행위입니다.

- **불규칙한 User-Agent** 또는 알려지지 않은 봇 특유의 문자열 사용  
- **짧은 시간 내 수백·수천 건의 페이지 요청**을 보내거나, 특정 리소스를 반복적으로 긁어가는 패턴  
- **IP 또는 대역폭 분산**을 통해 우회 시도를 하며, 여러 IP로 요청을 분산하는 공격 기법  
- 정상 크롤러(예: 검색 엔진 봇)와 달리 서버 리소스에 과도한 부담을 주거나 민감 정보를 무단으로 수집  

개별 요청만 보면 일반 트래픽으로 착각하기 쉽지만, **전체 로그**의 요청 패턴(반복성·시간 간격·User-Agent 등)을 보면 의심스러운 봇 활동이 드러나는 경우가 많습니다.

### 8) 콘텐츠 스크래핑(Content Scraping) 📰
경쟁 사이트나 악의적 목적으로 **대량의 페이지**를 수집하는 행위입니다.

- **짧은 시간 내 다수의 페이지**를 요청하거나, 특정 리소스를 집중적으로 긁어가는 패턴  
- 저작권이 있는 텍스트·이미지를 무단으로 복제하거나, **데이터 베이스**화하기 위해 공격적으로 스크래핑  
- 사이트 성능 저하, 서비스 비용 증가 등 간접적인 피해를 야기  

공격자는 마치 정상 사용자인 것처럼 접근하기 때문에, **개별 요청**만으로는 식별하기 어려우나, **전체 로그**에서의 집중적 요청 패턴을 보면 쉽게 파악 가능합니다.

### 9) DDoS 전조(Distributed Denial of Service) 사전 감지 ⏰
특정 IP 대역, 무작위 IP 등에서 **집중적으로 대량의 요청**이 발생하는 패턴을 파악하는 것입니다.

- 일반적인 트래픽 양과 비교해 **비정상적인 급증** 현상이 있는지 분석  
- **짧은 간격**으로 수많은 요청이 발생해 서버 리소스를 소모  
- APT 공격의 전초전으로 **트래픽 과부하**를 일으켜 보안 장비나 애플리케이션 장애를 유발하기도 함  

**실시간 로그** 모니터링을 통해 DDoS가 시작되기 전에 전조 현상을 빠르게 포착하면, 방화벽·WAF 설정 등을 조정하여 **피해를 최소화**할 수 있습니다.

### 10) XSS, SQL 인젝션 등 새로운 형태의 웹 취약점 시도 ⚠️
URL 파라메터나 POST Body에서 **스크립트 태그**(`<script>`)나 **SQL 구문**(SELECT, UNION 등)이 등장하는 등  
다양한 **웹 취약점 공격 패턴**을 시도하는 경우입니다.

- **다양한 인코딩**, **우회 기법**(이중 인코딩, 특수 문자 변환 등)을 혼합해 전통적인 필터를 무력화  
- 공격자가 신규 또는 변형된 페이로드를 삽입해, XSS·SQLi를 비롯한 RCE(Remote Code Execution) 등 유사 공격을 시도  
- **로그 전체**에서 의심스러운 문자열이 반복·집중적으로 나타나는지 파악해 탐지  

새로운 취약점이 발견되면, 보안 룰 업데이트 전에 공격이 발생할 가능성이 높으므로 **주기적인 로그 분석**으로 징후를 찾아내야 합니다.

### 11) API 오남용(API Abuse) 🚀
모바일·서드파티 애플리케이션 등을 통해 **비정상적인 API 호출**이 반복되는 경우입니다.

- **레이스 컨디션 공격**: 동일한 API를 초당 수백 건씩 호출해 데이터 불일치나 서버 에러를 유발  
- **대량 요청**을 통한 서비스 마비, 제한된 리소스(예: 메모리, CPU) 고갈  
- 허가되지 않은 데이터·기능에 접근하여 **정보 탈취**나 **부정 이용**을 시도  

API 요청 특성상 **서버 로그**나 **애플리케이션 로그**에 자세히 남지 않는 경우도 있어, **따로 수집**해 전체 맥락을 살펴보는 것이 중요합니다.

### 12) 내부 시스템 연동 모니터링(인사이드 아웃바운드 트래픽 포함) 🔍
방화벽 내부에서 외부로 나가는 **트래픽** 중 **비정상적인 요청**이 있는지 분석합니다.

- **내부 시스템 간 통신 로그**를 살펴 예상치 못한 연결(예: 관리자 포트, DB 접속 등)이 발생하는지 확인  
- 공격자는 내부망 침투 후, **수집한 데이터를 외부로 전송**(Exfiltration)하기 위해 특정 도메인·IP로 접속  
- **포트 스캐닝**, **터널링**, **프록시를 이용한 우회** 시도 등을 로그 분석으로 추적  

내부 시스템으로부터 나가는 연결도 함께 모니터링하면, **공격자의 움직임**을 조기에 발견·차단할 수 있습니다.

### 13) DNS / 도메인 변조 시도 🌐
특정 요청이 **의도치 않은 서브도메인**으로 리다이렉트되는 상황이나, DNS 엔트리가 **위·변조**되는 징후를 포착합니다.

- 로그 상에서 **도메인 미스매치**, **알 수 없는 CNAME** 정보, 과도한 DNS 요청이 발생하는지 확인  
- **DNS 하이재킹**으로 인해 사용자 트래픽이 악성 사이트로 유도되는 경우 발생  
- SSL 인증서 불일치나, **스푸핑** 시도 등도 함께 모니터링  

DNS는 **인프라의 기초**이므로, 이 부분이 변조되면 대규모 피해가 발생할 수 있어 철저한 로그 확인이 필수입니다.

### 14) 서버 에러 분석 및 장애 원인 추적 🩺
서버에서 발생하는 5xx 에러, 어플리케이션 충돌 로그 등을 **종합적으로** 분석합니다.

- **비정상적인 요청**이나 특정 파라메터로 인해 어플리케이션이 예외 상황(에러) 발생  
- **보안 취약점**으로 이어지거나 **운영상 장애**가 혼재해 시스템 가용성을 떨어뜨림  
- 로그를 통해 **오류 발생 시점**과 **공격 시도**를 연계해 원인을 정확히 파악 가능  

보안 문제와 운영 문제를 동시에 진단할 수 있어, **로깅·모니터링 인프라**가 매우 중요합니다.

### 15) 공격 페이로드 우회 기법 감지(WAF Bypass 시도) 👀
URL 인코딩, 이중 인코딩, 특수 문자 치환 등을 활용해 **WAF나 보안 솔루션 우회를 시도**하는 패턴입니다.

- 기존 룰에 걸리지 않도록 **특수 문자**를 다른 형태로 변환, `script`를 `scr\<ip\>t` 등으로 분할  
- 정상적인 요청과 섞여 **의도적으로 작은 페이로드**를 여러 번 나눠 보내기도 함  
- **전체 로그**에서 변조·인코딩된 문자열이 반복·집중적으로 나타나는지 모니터링  

이런 우회 기법은 개별 요청만 보면 정당한 트래픽처럼 보이기도 하므로, **종합적인 패턴 분석**이 필수입니다.

### 16) 이상 트래픽 시간대 분석 및 동적 방어 정책 생성 🕒
심야, 주말 같은 **특정 시간대**에만 급증하는 **의심스러운 트래픽**을 사전에 파악합니다.

- 일반 사용자 활동이 적은 시간에 **집중 공격**을 시도해 발견·대응을 늦추려는 전략  
- 해당 시간대에 반복적으로 **동일 IP 대역**에서 접근이 이루어지는지 확인  
- **자동 대응 정책**(IP 차단, 토큰 검증 강화, CAPTCHA 등)을 동적으로 적용해 피해 최소화  

이상 트래픽 패턴을 **실시간으로** 분석하면, 공격 발생 전에 조치하여 **사전 방어**가 가능합니다.

---

## ✍️ 결론

단순히 GET/POST 로그만 분리해서 보는 것이 아니라, **전체 웹 로그**를 종합적으로 분석하는 것이 보안상 매우 중요합니다.

- **제로데이와 같은 신종 공격**을 조기에 식별하고,  
- **크리덴셜 스터핑**처럼 여러 단계를 거치는 공격 패턴을 파악하며,  
- **웹쉘 업로드**나 **파라메터 변조**, **세션 하이재킹** 등의 APT 초기 단계를 추적하고,  
- **멀티벡터 공격** 전반은 물론, 봇 탐지·콘텐츠 스크래핑·DDoS 전조·WAF 우회 공격 등 **다양한 위협**에 대응  

이는 모두 **로그를 전체적으로 보고 분석**했을 때 얻을 수 있는 핵심적인 이점들입니다.

**특히, POST 요청 로그에서 Body 영역**을 살피는 것은 더욱 중요합니다. HTTP Body에 숨겨진 파라메터나 악성 페이로드를 감지하기 위해서는,  
단순히 URL만으로는 부족하고 **POST Body까지 포함한 전체 로그**를 확보·분석해야 합니다.  
이처럼 **POST 데이터를 철저히 모니터링**한다면, 서버에 직접 악성 파일이 업로드되거나 중요한 파라메터가 변조되는 공격을 한층 빠르게 잡아낼 수 있습니다.

오늘날 공격자들은 기발하고 복잡한 기법을 활용해 웹 서버를 노립니다.  
그러므로 실제 운영 환경에서 보안 위협을 **선제적으로** 막기 위해서는,  
**GET/POST를 포함한 모든 트래픽 로그**를 **실시간** 혹은 **준실시간**으로 살피고,  
분석 결과를 바탕으로 빠른 대응이 가능하도록 환경을 구축하는 것이 매우 중요합니다.

---

### 📖 **함께 읽기**  
- [PLURA-Blog: 우리는 왜 GET/POST 로그를 분석하는가?](https://blog.plura.io/ko/column/why_analyze_get_post_logs/)  
